seed : 42

data : 
  train_batch_size : 16
  val_batch_size : 16
  test_batch_size : 16
  tokenizer_max_len : 256

train :
  num_train_epoch : 20
  weight_decay : 0.0001
  learning_rate : 1e-5
  lr_scheduler : stepLR

model :
  model_name : klue/roberta-large

wandb :
  project_name : klue-bert-base_tuning

path:
  model : /opt/ml/level2_klue-nlp-08/model/klue/bert-base/2023-05-08 14:47:42.317246/epoch=2-step=4872.ckpt
  train : ./dataset/train/train.csv
  dev : ./dataset/train/val.csv
  test : ./dataset/test/test.csv

  
